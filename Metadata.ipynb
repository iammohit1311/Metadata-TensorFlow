{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648d7b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 17:19:15.284395: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-24 17:19:15.285995: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-24 17:19:15.315493: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-24 17:19:15.316271: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-24 17:19:16.055351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tflite_support.metadata_writers import object_detector\n",
    "from tflite_support.metadata_writers import writer_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e263a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"ObjectDetector\",\n",
      "  \"description\": \"Identify which of a known set of objects might be present and provide information about their positions within the given image or a video stream.\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"image\",\n",
      "          \"description\": \"Input image to be detected.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"ImageProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"color_space\": \"RGB\"\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"NormalizationOptions\",\n",
      "              \"options\": {\n",
      "                \"mean\": [\n",
      "                  127.5\n",
      "                ],\n",
      "                \"std\": [\n",
      "                  127.5\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              -1.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"location\",\n",
      "          \"description\": \"The locations of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"BoundingBoxProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"index\": [\n",
      "                1,\n",
      "                0,\n",
      "                3,\n",
      "                2\n",
      "              ],\n",
      "              \"type\": \"BOUNDARIES\"\n",
      "            },\n",
      "            \"range\": {\n",
      "              \"min\": 2,\n",
      "              \"max\": 2\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_groups\": [\n",
      "        {\n",
      "          \"name\": \"detection_result\",\n",
      "          \"tensor_names\": [\n",
      "            \"location\",\n",
      "            \"category\",\n",
      "            \"score\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit.srivastava@Brightlifecare.local/.local/lib/python3.10/site-packages/tensorflow_lite_support/metadata/python/metadata.py:395: UserWarning: File, 'labelmap.txt', does not exist in the metadata. But packing it to tflite model is still allowed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ObjectDetectorWriter = object_detector.MetadataWriter\n",
    "_MODEL_PATH = \"/home/mohit.srivastava@Brightlifecare.local/Desktop/YOLOv8 Model/yolov8.tflite\"\n",
    "# Task Library expects label files that are in the same format as the one below.\n",
    "_LABEL_FILE = \"/home/mohit.srivastava@Brightlifecare.local/Desktop/YOLOv8 Model/labelmap.txt\"\n",
    "_SAVE_TO_PATH = \"/home/mohit.srivastava@Brightlifecare.local/Desktop/YOLOv8 Model/yolo_head.tflite\"\n",
    "# Normalization parameters is required when reprocessing the image. It is\n",
    "# optional if the image pixel values are in range of [0, 255] and the input\n",
    "# tensor is quantized to uint8. See the introduction for normalization and\n",
    "# quantization parameters below for more details.\n",
    "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
    "_INPUT_NORM_MEAN = 127.5\n",
    "_INPUT_NORM_STD = 127.5\n",
    "\n",
    "# Create the metadata writer.\n",
    "writer = ObjectDetectorWriter.create_for_inference(\n",
    "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
    "    [_LABEL_FILE])\n",
    "\n",
    "# Verify the metadata generated by metadata writer.\n",
    "print(writer.get_metadata_json())\n",
    "\n",
    "# Populate the metadata into the model.\n",
    "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ae40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
